import streamlit as st
import hmac
st.set_page_config(
    page_title="AI-–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç",
    page_icon="üí°",
    layout="wide",
    initial_sidebar_state="expanded"
)
from streamlit_extras.badges import badge
from streamlit_extras.metric_cards import style_metric_cards
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from openai import OpenAI
import os
import tempfile
import gdown
import re
import zipfile
import shutil
import logging
import time
import datetime
import hashlib
from functools import lru_cache
import matplotlib.pyplot as plt
import numpy as np
from numpy import dot
from numpy.linalg import norm

# --- –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –ø–∞—Ä–æ–ª—é —á–µ—Ä–µ–∑ Streamlit secrets ---
def check_password():
    """Returns True if the user entered the correct password."""
    if "password_correct" in st.session_state:
        return st.session_state.password_correct
    
    def password_entered():
        """Checks whether a password entered by the user is correct."""
        if hmac.compare_digest(st.session_state.password, st.secrets.get("PASSWORD", "default_password")):
            st.session_state.password_correct = True
            del st.session_state.password  # –ù–µ —Ö—Ä–∞–Ω–∏–º –ø–∞—Ä–æ–ª—å –≤ —Å–µ—Å—Å–∏–∏
        else:
            st.session_state.password_correct = False
    
    st.text_input(
        "–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é", 
        type="password",
        key="password",
        on_change=password_entered
    )
    
    if "password_correct" in st.session_state:
        if not st.session_state.password_correct:
            st.error("üòï –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
            return False
    
    return False

# –ï—Å–ª–∏ –ø–∞—Ä–æ–ª—å –Ω–µ–≤–µ—Ä–Ω—ã–π, –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if not check_password():
    st.stop()

# –û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ Streamlit
st.markdown("""
<style>
    .relevance-high {
        color: green;
        font-size: 0.8rem;
        text-align: right;
    }
    .relevance-medium {
        color: orange;
        font-size: 0.8rem;
        text-align: right;
    }
    .relevance-low {
        color: red;
        font-size: 0.8rem;
        text-align: right;
    }
    .source-info {
        background-color: #f0f2f6;
        border-radius: 5px;
        padding: 10px;
        margin-top: 10px;
        border-left: 3px solid #4CAF50;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.2rem;
    }
    div[data-testid="stMetricDelta"] {
        font-size: 0.8rem;
    }
    .metadata {
        font-size: 0.8rem;
        color: #666;
        text-align: right;
    }
    .base-knowledge {
        border-left: 3px solid #4CAF50;
        padding-left: 10px;
        background-color: #f0f8f0;
    }
    .additional-knowledge {
        border-left: 3px solid #FFA500;
        padding-left: 10px;
        background-color: #fff8f0;
    }
    .no-knowledge {
        border-left: 3px solid #FF0000;
        padding-left: 10px;
        background-color: #fff0f0;
    }
    .source-header {
        font-weight: bold;
        margin-top: 10px;
    }
    .relevance-bar {
        height: 8px;
        border-radius: 4px;
        margin-bottom: 5px;
    }
    .mode-badge {
        padding: 5px 10px;
        border-radius: 10px;
        font-weight: bold;
        font-size: 0.8rem;
        display: inline-block;
    }
    .mode-strict {
        background-color: #ffcccc;
        color: #990000;
    }
    .mode-balanced {
        background-color: #fff2cc;
        color: #806600;
    }
    .mode-flexible {
        background-color: #d9ead3;
        color: #274e13;
    }
</style>
""", unsafe_allow_html=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('app.log')
    ]
)
logger = logging.getLogger('ai-consultant')

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
if "faiss_db" not in st.session_state:
    st.session_state.faiss_db = None
if "faiss_path" not in st.session_state:
    st.session_state.faiss_path = None
if "doc_count" not in st.session_state:
    st.session_state.doc_count = 0
if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_context" not in st.session_state:
    st.session_state.conversation_context = ""
if "model" not in st.session_state:
    st.session_state.model = "gpt-4o-mini"
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.4
if "max_token" not in st.session_state:
    st.session_state.max_token = 2000
if "use_chunk" not in st.session_state:
    st.session_state.use_chunk = 4
if "temp_dir" not in st.session_state:
    st.session_state.temp_dir = tempfile.mkdtemp()
if "knowledge_mode" not in st.session_state:
    st.session_state.knowledge_mode = "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π"
if "show_sources" not in st.session_state:
    st.session_state.show_sources = False
if "search_analytics" not in st.session_state:
    st.session_state.search_analytics = {
        "queries": [],
        "no_results_queries": [],
        "avg_docs_found": 0,
        "total_docs_found": 0,
        "query_count": 0
    }
if "max_context_turns" not in st.session_state:
    st.session_state.max_context_turns = 10

# –ó–∞–≥—Ä—É–∑–∫–∞ API-–∫–ª—é—á–∞ –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤ Streamlit
api_key = st.secrets.get("OPENAI_API_KEY")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è API-–∫–ª—é—á–∞
if not api_key:
    st.error("‚ùå –û—à–∏–±–∫–∞: API-–∫–ª—é—á OpenAI –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    st.stop()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = OpenAI(api_key=api_key)

def validate_google_drive_url(url):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Å—ã–ª–∫–∏ Google Drive."""
    if 'file' in url:
        patterns = [
            r'drive\.google\.com/file/d/([^/]+)',
            r'drive\.google\.com/open\?id=([^&]+)'
        ]
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return True, match.group(1), 'file'
    if 'folders' in url:
        pattern = r'drive\.google\.com/drive/folders/([^/?&#]+)'
        match = re.search(pattern, url)
        if match:
            return True, match.group(1), 'folder'
    return False, None, None

def download_file_from_drive(file_id, output_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –∏–∑ Google Drive."""
    try:
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –∏–∑ Google Drive..."):
            direct_url = f"https://drive.google.com/uc?id={file_id}&export=download"
            gdown.download(direct_url, output_path, quiet=True)
            return output_path
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ –∏–∑ Google Drive: {str(e)}")
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ –∏–∑ Google Drive: {str(e)}")
        return None

def download_from_drive_folder(folder_id, output_dir):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ Google Drive."""
    try:
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ Google Drive..."):
            folder_url = f"https://drive.google.com/drive/folders/{folder_id}"
            files = gdown.download_folder(
                folder_url,
                output=output_dir,
                quiet=True,
                use_cookies=False
            )
            return files
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ Google Drive: {str(e)}")
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ Google Drive: {str(e)}")
        return []

def load_faiss_db(faiss_path, embeddings=None):
    """–ó–∞–≥—Ä—É–∑–∫–∞ FAISS –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    try:
        if embeddings is None:
            embeddings = OpenAIEmbeddings()
        db = FAISS.load_local(faiss_path, embeddings, allow_dangerous_deserialization=True)
        doc_count = len(db.index_to_docstore_id) if hasattr(db, 'index_to_docstore_id') else "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        st.session_state.faiss_db = db
        st.session_state.faiss_path = faiss_path
        st.session_state.doc_count = doc_count
        logger.info(f"–ë–∞–∑–∞ FAISS —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {doc_count}")
        return db, doc_count
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ FAISS: {e}")
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ FAISS: {e}")
        return None, 0

def get_system_message(knowledge_mode, has_relevant_docs, conversation_context_exists):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã."""
    base_message = "–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∞—é—â–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π. "
    
    mode_instructions = {
        "–°—Ç—Ä–æ–≥–∏–π": """
            –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –≤ –°–¢–†–û–ì–û–ú —Ä–µ–∂–∏–º–µ. –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:
            1. –û—Ç–≤–µ—á–∞–π –ò–°–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
            2. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî —á–µ—Ç–∫–æ —Å–∫–∞–∂–∏: '–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É'.
            3. –ù–ï –ò–°–ü–û–õ–¨–ó–£–ô –Ω–∏–∫–∞–∫–∏–µ –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –∫–∞–∂—É—Ç—Å—è –æ—á–µ–≤–∏–¥–Ω—ã–º–∏.
            4. –ù–ò–ö–û–ì–î–ê –Ω–µ –ø—ã—Ç–∞–π—Å—è —É–≥–∞–¥–∞—Ç—å –∏–ª–∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö.
            5. –¢–æ—á–Ω–æ—Å—Ç—å –≤–∞–∂–Ω–µ–µ –ø–æ–ª–Ω–æ—Ç—ã ‚Äî –ª—É—á—à–µ –¥–∞—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–π, –Ω–æ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç.
        """,
        "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π": """
            –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –≤ –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–û–ú —Ä–µ–∂–∏–º–µ. –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:
            1. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.
            2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ–ø–æ–ª–Ω–∞—è ‚Äî –º–æ–∂–µ—à—å –¥–æ–ø–æ–ª–Ω–∏—Ç—å –µ—ë, –Ω–æ —á—ë—Ç–∫–æ –æ—Ç–º–µ—Ç—å.
            3. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º, –Ω–æ –º–æ–∂–µ—à—å –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –æ–±—â–∏–π –æ—Ç–≤–µ—Ç.
            4. –°—Ç–∞—Ä–∞–π—Å—è –Ω–∞–π—Ç–∏ –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é (–∏–∑ –±–∞–∑—ã) –∏ –ø–æ–ª–Ω–æ—Ç–æ–π (–æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è).
        """,
        "–ì–∏–±–∫–∏–π": """
            –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –≤ –ì–ò–ë–ö–û–ú —Ä–µ–∂–∏–º–µ. –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:
            1. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–∞–∫ –æ—Å–Ω–æ–≤—É, –Ω–æ —Å–º–µ–ª–æ –¥–æ–ø–æ–ª–Ω—è–π –µ—ë.
            2. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —á–∞—Å—Ç–∏—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ‚Äî —Ä–∞—Å—à–∏—Ä—å –µ—ë —Å–≤–æ–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏.
            3. –î–∞–∂–µ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å—Ç–∞—Ä–∞–π—Å—è –¥–∞—Ç—å –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç.
            4. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
            5. –û—Ç–º–µ—á–∞–π, –≥–¥–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.
        """
    }
    
    search_status = (
        "–í–ê–ñ–ù–û: –í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ù–ï –ù–ê–ô–î–ï–ù–û –ø—Ä—è–º–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
        if not has_relevant_docs else
        "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –æ—Ç–Ω–æ—Å—è—â—É—é—Å—è –∫ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
    )
    
    dialog_status = (
        "–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."
        if conversation_context_exists else
        "–≠—Ç–æ –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∏–ª–∏ –Ω–æ–≤–∞—è —Ç–µ–º–∞."
    )
    
    final_instructions = """
        –ü—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å:
        1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º.
        2. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ª–æ–≥–∏—á–µ—Å–∫–∏.
        3. –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏ –∏ –≤—ã–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏.
        4. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –º–Ω–æ–≥–æ—Å–æ—Å—Ç–∞–≤–Ω—ã–π, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤—Å–µ –µ–≥–æ —á–∞—Å—Ç–∏.
        5. –¢–≤–æ—è —Ü–µ–ª—å ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ —Ä–∞–º–∫–∞—Ö –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã.
    """
    
    return f"{base_message}\n\n{mode_instructions[knowledge_mode]}\n\n{search_status}\n\n{dialog_status}\n\n{final_instructions}"

@lru_cache(maxsize=50)
def cached_search(query_hash, k, knowledge_mode):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π."""
    try:
        results = st.session_state.faiss_db.similarity_search_with_score(query_hash, k=k)
        
        thresholds = {
            "–°—Ç—Ä–æ–≥–∏–π": 0.8,
            "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π": 0.6,
            "–ì–∏–±–∫–∏–π": 0.4
        }
        threshold = thresholds.get(knowledge_mode, 0.5)
        
        filtered_results = [(doc, score) for doc, score in results if score < threshold]
        return filtered_results, len(filtered_results) > 0
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
        return [], False

def estimate_tokens(text):
    """–û—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ."""
    return len(text.split()) * 1.5

def update_conversation_context():
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."""
    relevant_messages = st.session_state.messages[-st.session_state.max_context_turns*2:] if len(st.session_state.messages) > st.session_state.max_context_turns*2 else st.session_state.messages
    
    context_parts = []
    for i in range(0, len(relevant_messages), 2):
        if i+1 < len(relevant_messages):
            user_msg = relevant_messages[i]["content"]
            assistant_msg = relevant_messages[i+1]["content"]
            context_parts.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_msg}\n–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {assistant_msg}")
    
    st.session_state.conversation_context = "\n\n".join(context_parts)
    logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. –†–∞–∑–º–µ—Ä: {len(st.session_state.conversation_context)} —Å–∏–º–≤–æ–ª–æ–≤")

def answer_query(query):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    start_time = time.time()
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö
        general_questions = ["—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å", "–ø–æ–º–æ—â—å", "—Å–ø—Ä–∞–≤–∫–∞", "–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏", "–∫–æ–º–∞–Ω–¥—ã"]
        if any(q in query.lower() for q in general_questions):
            capabilities = f"""
            # –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ AI-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞

            –Ø AI-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å —Ñ—É–Ω–∫—Ü–∏–µ–π –∞–Ω–∞–ª–∏–∑–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π. –Ø –º–æ–≥—É:

            1. –ò—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∑–∞–¥–∞–Ω–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ –≤–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º
            2. –û—Ç–≤–µ—á–∞—Ç—å —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            3. –†–∞–±–æ—Ç–∞—Ç—å –≤ —Ç—Ä–µ—Ö —Ä–µ–∂–∏–º–∞—Ö:
               - **–°—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º**: –æ—Ç–≤–µ—á–∞—é –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
               - **–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º**: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —Å –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è–º–∏
               - **–ì–∏–±–∫–∏–π —Ä–µ–∂–∏–º**: –∏—Å–ø–æ–ª—å–∑—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è–º–∏
            
            –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: **{st.session_state.knowledge_mode}**
            
            –ó–∞–¥–∞–π—Ç–µ –º–Ω–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –Ω–∞ –Ω–µ–≥–æ –æ—Ç–≤–µ—Ç–∏—Ç—å!
            """
            logger.info(f"–ó–∞–ø—Ä–æ—Å –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö. –í—Ä–µ–º—è: {time.time() - start_time:.2f}—Å")
            return capabilities, {"relevance": 1.0, "docs_count": 0, "query_time": time.time() - start_time}
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        if not st.session_state.faiss_db:
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –±–µ–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
            return "‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ FAISS –±–∞–∑—É –≤ –±–æ–∫–æ–≤–æ–º –º–µ–Ω—é.", {"relevance": 0, "docs_count": 0, "query_time": time.time() - start_time}
        
        # –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        logger.info(f"–ü–æ–∏—Å–∫ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
        with st.spinner("üîç –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏..."):
            docs_with_scores, has_relevant_docs = cached_search(query, st.session_state.use_chunk, st.session_state.knowledge_mode)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        docs = [doc for doc, _ in docs_with_scores]
        scores = [score for _, score in docs_with_scores]
        avg_relevance = sum(scores) / len(scores) if scores else 1.0
        rel_score = 1 / (1 + avg_relevance)  # 0..1, –≥–¥–µ 1 ‚Äî –∏–¥–µ–∞–ª—å–Ω–æ
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        st.session_state.search_analytics["queries"].append(query)
        st.session_state.search_analytics["query_count"] += 1
        st.session_state.search_analytics["total_docs_found"] += len(docs)
        st.session_state.search_analytics["avg_docs_found"] = (
            st.session_state.search_analytics["total_docs_found"] / 
            st.session_state.search_analytics["query_count"]
        )
        
        if not has_relevant_docs:
            st.session_state.search_analytics["no_results_queries"].append(query)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context = "\n\n".join([doc.page_content for doc in docs])
        max_context_tokens = 4000 if "gpt-4" in st.session_state.model else 3000
        
        if st.session_state.conversation_context:
            enhanced_context = st.session_state.conversation_context + "\n\n" + context
        else:
            enhanced_context = context
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        while estimate_tokens(enhanced_context) > max_context_tokens and len(docs) > 1:
            docs = docs[:-1]
            context = "\n\n".join([doc.page_content for doc in docs])
            enhanced_context = st.session_state.conversation_context + "\n\n" + context if st.session_state.conversation_context else context
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        system_message = get_system_message(
            st.session_state.knowledge_mode,
            has_relevant_docs,
            bool(st.session_state.conversation_context)
        )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        with st.spinner("üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞..."):
            messages = [
                {"role": "system", "content": system_message},
                *st.session_state.messages,
                {"role": "user", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞:\n\n{enhanced_context}\n\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}"}
            ]
            
            response = client.chat.completions.create(
                model=st.session_state.model,
                messages=messages,
                temperature=st.session_state.temperature,
                max_tokens=st.session_state.max_token,
            )
            
            answer = response.choices[0].message.content
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        if st.session_state.knowledge_mode in ["–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π", "–ì–∏–±–∫–∏–π"]:
            if "–ù–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π" not in answer and "–°–æ–≥–ª–∞—Å–Ω–æ –±–∞–∑–µ" not in answer and has_relevant_docs:
                base_pattern = r'(.*?)(?:–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ|–û–¥–Ω–∞–∫–æ|–í–ø—Ä–æ—á–µ–º| –º–æ–≥—É –¥–æ–±–∞–≤–∏—Ç—å| —Å—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å)'
                match = re.search(base_pattern, answer, re.DOTALL)
                
                if match:
                    base_part = match.group(1).strip()
                    additional_part = answer[len(base_part):].strip()
                    
                    formatted_answer = f"<div class='base-knowledge'>{base_part}</div>\n\n"
                    if additional_part:
                        formatted_answer += f"<div class='additional-knowledge'>{additional_part}</div>"
                    
                    answer = formatted_answer
        
        if not has_relevant_docs and st.session_state.knowledge_mode == "–°—Ç—Ä–æ–≥–∏–π":
            answer = f"<div class='no-knowledge'>{answer}</div>"
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –º–µ—Ç—Ä–∏–∫
        if not st.session_state.conversation_context:
            st.session_state.conversation_context = answer
        else:
            st.session_state.conversation_context += f"\n\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–æ—Å–∏–ª: {query}\n\n–û—Ç–≤–µ—Ç: {answer}"
        
        query_time = time.time() - start_time
        
        logger.info(f"–ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {query_time:.2f}—Å, –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {rel_score:.4f}")
        
        # –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        docs_data = [
            {
                "page_content": doc.page_content,
                "metadata": doc.metadata if hasattr(doc, 'metadata') else {}
            }
            for doc in docs
        ]
        
        return answer, {
            "relevance": rel_score,
            "docs_count": len(docs),
            "docs_data": docs_data,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—É—é –≤–µ—Ä—Å–∏—é
            "query_time": query_time,
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "mode": st.session_state.knowledge_mode
        }
        
    except Exception as e:
        error_message = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"
        logger.error(error_message)
        return error_message, {"relevance": 0, "docs_count": 0, "query_time": time.time() - start_time}

# --- SIDEBAR: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ---
with st.sidebar:
    st.header("üíæ –ó–∞–≥—Ä—É–∑–∫–∞ FAISS –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    upload_method = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ FAISS –±–∞–∑—ã:", ["–õ–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä", "Google Drive"], horizontal=True)
    
    if upload_method == "–õ–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä":
        col1, col2 = st.columns(2)
        with col1:
            faiss_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ index.faiss —Ñ–∞–π–ª", type=["faiss"])
        with col2:
            pkl_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ index.pkl —Ñ–∞–π–ª", type=["pkl"])
        if faiss_file and pkl_file:
            faiss_dir = os.path.join(st.session_state.temp_dir, "faiss_index")
            os.makedirs(faiss_dir, exist_ok=True)
            with open(os.path.join(faiss_dir, "index.faiss"), "wb") as f:
                f.write(faiss_file.getbuffer())
            with open(os.path.join(faiss_dir, "index.pkl"), "wb") as f:
                f.write(pkl_file.getbuffer())
            if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å FAISS –±–∞–∑—É"):
                with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É..."):
                    embeddings = OpenAIEmbeddings()
                    db, doc_count = load_faiss_db(faiss_dir, embeddings)
                    if db:
                        st.success(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {doc_count}")
    else:  # Google Drive
        st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ —Å Google Drive –ø–æ –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–µ")
        drive_url = st.text_input("–°—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª –∏–ª–∏ –ø–∞–ø–∫—É –≤ Google Drive")
        if drive_url:
            if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å Google Drive"):
                is_valid, id_value, url_type = validate_google_drive_url(drive_url)
                if is_valid:
                    if url_type == 'file':
                        if '.zip' in drive_url.lower():
                            with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –∏ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤..."):
                                zip_path = os.path.join(st.session_state.temp_dir, "faiss_base.zip")
                                zip_success = download_file_from_drive(id_value, zip_path)
                                if zip_success:
                                    extract_dir = os.path.join(st.session_state.temp_dir, "extracted_faiss")
                                    os.makedirs(extract_dir, exist_ok=True)
                                    try:
                                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                                            zip_ref.extractall(extract_dir)
                                        faiss_file = os.path.join(extract_dir, "index.faiss")
                                        pkl_file = os.path.join(extract_dir, "index.pkl")
                                        if os.path.exists(faiss_file) and os.path.exists(pkl_file):
                                            faiss_dir = os.path.join(st.session_state.temp_dir, "faiss_index")
                                            os.makedirs(faiss_dir, exist_ok=True)
                                            shutil.copy2(faiss_file, os.path.join(faiss_dir, "index.faiss"))
                                            shutil.copy2(pkl_file, os.path.join(faiss_dir, "index.pkl"))
                                            embeddings = OpenAIEmbeddings()
                                            db, doc_count = load_faiss_db(faiss_dir, embeddings)
                                            if db:
                                                st.success(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –∞—Ä—Ö–∏–≤–∞! –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {doc_count}")
                                        else:
                                            st.error("–í –∞—Ä—Ö–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã index.faiss –∏ index.pkl")
                                    except Exception as e:
                                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ –∞—Ä—Ö–∏–≤–∞: {e}")
                                else:
                                    st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞—Ä—Ö–∏–≤–∞ —Å Google Drive")
                        else:
                            st.warning("–°—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω–∞ —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ ZIP-–∞—Ä—Ö–∏–≤ —Å –±–∞–∑–æ–π –∏–ª–∏ –Ω–∞ –ø–∞–ø–∫—É, —Å–æ–¥–µ—Ä–∂–∞—â—É—é —Ñ–∞–π–ª—ã –±–∞–∑—ã")
                    elif url_type == 'folder':
                        with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏..."):
                            output_dir = os.path.join(st.session_state.temp_dir, "drive_folder")
                            os.makedirs(output_dir, exist_ok=True)
                            files = download_from_drive_folder(id_value, output_dir)
                            if files:
                                faiss_file = None
                                pkl_file = None
                                for file in files:
                                    if file.endswith("index.faiss"):
                                        faiss_file = file
                                    elif file.endswith("index.pkl"):
                                        pkl_file = file
                                if faiss_file and pkl_file:
                                    faiss_dir = os.path.join(st.session_state.temp_dir, "faiss_index")
                                    os.makedirs(faiss_dir, exist_ok=True)
                                    shutil.copy2(faiss_file, os.path.join(faiss_dir, "index.faiss"))
                                    shutil.copy2(pkl_file, os.path.join(faiss_dir, "index.pkl"))
                                    embeddings = OpenAIEmbeddings()
                                    db, doc_count = load_faiss_db(faiss_dir, embeddings)
                                    if db:
                                        st.success(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –ø–∞–ø–∫–∏! –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {doc_count}")
                                else:
                                    st.error("–í –ø–∞–ø–∫–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã index.faiss –∏ index.pkl")
                            else:
                                st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ Google Drive")
                else:
                    st.error("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å—Å—ã–ª–∫–∏ Google Drive")
    
    # –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    st.header("–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã")
    st.session_state.knowledge_mode = st.select_slider(
        "–†–µ–∂–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:",
        options=["–ì–∏–±–∫–∏–π", "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π", "–°—Ç—Ä–æ–≥–∏–π"],
        value=st.session_state.knowledge_mode,
        help="–ì–∏–±–∫–∏–π - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–∞–∑—É –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ, –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π, –°—Ç—Ä–æ–≥–∏–π - —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã"
    )

    # –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞
    if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞"):
        st.session_state.messages = []
        st.session_state.conversation_context = ""
        st.rerun()

    # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∏–∞–ª–æ–≥–∞ —Ç–µ–ø–µ—Ä—å –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞
    if st.button("üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞"):
        chat_export = "\n\n".join([
            f"{'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å' if msg['role'] == 'user' else '–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç'}: {msg['content']}"
            for msg in st.session_state.messages
        ])
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å –¥–∏–∞–ª–æ–≥",
            data=chat_export,
            file_name=f"chat_export_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
            mime="text/plain"
        )

    # --- –ù–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ---
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    st.session_state.model = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", ["gpt-4o-mini", "gpt-4o", "gpt-4.1"], index=0)
    st.session_state.temperature = st.slider("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:", 0.0, 2.0, 0.4, 0.1)
    st.session_state.max_token = st.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤:", 1500, 4000, 2000, 100)
    st.session_state.use_chunk = st.slider("–ß–∏—Å–ª–æ –±–ª–æ–∫–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:", 4, 10, 4, 1)

# --- MAIN: –ß–∞—Ç ---
st.title("AI-–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç")

# –°—Ç–∞—Ç—É—Å —Å–µ—Å—Å–∏–∏
st.markdown("---")
col1, col2, col3 = st.columns(3)
with col1:
    st.markdown(f"**–†–µ–∂–∏–º:** {st.session_state.knowledge_mode}")
with col2:
    st.markdown(f"**–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ:** {st.session_state.doc_count}")
with col3:
    if st.session_state.faiss_db:
        st.markdown("**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ê–∫—Ç–∏–≤–µ–Ω")
    else:
        st.markdown("**–°—Ç–∞—Ç—É—Å:** ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –±–∞–∑—ã")

# –ß–∞—Ç
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"], unsafe_allow_html=True)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
if prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∞—Ç—É—Å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –±–ª–æ–∫–µ (–Ω–µ –≤–Ω—É—Ç—Ä–∏ —Å–æ–æ–±—â–µ–Ω–∏—è)
    status_container = st.empty()
    with status_container.status("üîç –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏...", expanded=True) as status:
        status.update(label="–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π...", state="running")
        answer, metadata = answer_query(prompt)
        status.update(label="–ì–æ—Ç–æ–≤–æ!", state="complete")
    # –°–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    status_container.empty()
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ—Ç–≤–µ—Ç –≤ —á–∞—Ç–µ
    with st.chat_message("assistant"):
        st.markdown(answer, unsafe_allow_html=True)
        relevance_color = "green" if metadata["relevance"] > 0.8 else "orange" if metadata["relevance"] > 0.5 else "red"
        st.markdown(
            f"<div style='text-align: right'><small style='color: {relevance_color}'>"
            f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {metadata['relevance']:.0%}</small></div>",
            unsafe_allow_html=True
        )
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
    st.session_state.messages.append({
        "role": "assistant",
        "content": answer,
        "sources": metadata.get("docs_data", [])  # –¢–µ–ø–µ—Ä—å —ç—Ç–æ JSON-—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–µ —Å–ª–æ–≤–∞—Ä–∏
    })
